{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras Custom Callbacks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOHCWjz0cTaxrA47UdIEOSg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prashant-bande/Keras-Custom-Callbacks/blob/master/Keras_Custom_Callbacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh3c0z59VQiI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "227a628d-03c4-41de-cd36-9d9fdf92de8e"
      },
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfq3EEGnWGQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the Keras model to add callbacks to\n",
        "def get_model():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Dense(1, activation = 'linear', input_dim = 784))\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.1), loss='mean_squared_error', metrics=['mae'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QQqlYW6WGTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load example MNIST data and pre-process it\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
        "x_test = x_test.reshape(10000, 784).astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIEtQYjBWGOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a simple custom callback to track the start and end of every batch of data. During those calls, it prints the index of the current batch.\n",
        "\n",
        "import datetime\n",
        "\n",
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "  def on_train_batch_begin(self, batch, logs=None):\n",
        "    print('Training: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
        "  def on_train_batch_end(self, batch, logs=None):\n",
        "    print('Training: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))\n",
        "  def on_test_batch_begin(self, batch, logs=None):\n",
        "    print('Evaluating: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
        "  def on_test_batch_end(self, batch, logs=None):\n",
        "    print('Evaluating: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eICjWjF9XSHL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "outputId": "41640751-9a49-434d-861f-af180a012111"
      },
      "source": [
        "# Providing a callback to model methods such as tf.keras.Model.fit()\n",
        "\n",
        "model = get_model()\n",
        "_ = model.fit(x_train, \n",
        "              y_train, \n",
        "              batch_size=64, \n",
        "              epochs=1, \n",
        "              steps_per_epoch=5, \n",
        "              verbose=0, \n",
        "              callbacks=[MyCustomCallback()])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: batch 0 begins at 10:23:54.555681\n",
            "Training: batch 0 ends at 10:23:54.810132\n",
            "Training: batch 1 begins at 10:23:54.810573\n",
            "Training: batch 1 ends at 10:23:54.812571\n",
            "Training: batch 2 begins at 10:23:54.813202\n",
            "Training: batch 2 ends at 10:23:54.814715\n",
            "Training: batch 3 begins at 10:23:54.815062\n",
            "Training: batch 3 ends at 10:23:54.818405\n",
            "Training: batch 4 begins at 10:23:54.818670\n",
            "Training: batch 4 ends at 10:23:54.821177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6Ar8_jaYNQz",
        "colab_type": "text"
      },
      "source": [
        "## Model methods that take callbacks\n",
        "Users can supply a list of callbacks to the following `tf.keras.Model` methods:\n",
        "#### [`fit()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit), [`fit_generator()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit_generator)\n",
        "Trains the model for a fixed number of epochs (iterations over a dataset, or data yielded batch-by-batch by a Python generator).\n",
        "#### [`evaluate()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate), [`evaluate_generator()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate_generator)\n",
        "Evaluates the model for given data or data generator. Outputs the loss and metric values from the evaluation.\n",
        "#### [`predict()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict), [`predict_generator()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict_generator)\n",
        "Generates output predictions for the input data or data generator.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nydyKA8wXSMq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "outputId": "3a8d9b62-5bba-4d1b-b191-8f18fd8ac399"
      },
      "source": [
        "_ = model.evaluate(x_test, y_test, batch_size=128, verbose=0, steps=5, callbacks=[MyCustomCallback()])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating: batch 0 begins at 10:23:54.864761\n",
            "Evaluating: batch 0 ends at 10:23:54.918712\n",
            "Evaluating: batch 1 begins at 10:23:54.919302\n",
            "Evaluating: batch 1 ends at 10:23:54.921205\n",
            "Evaluating: batch 2 begins at 10:23:54.922316\n",
            "Evaluating: batch 2 ends at 10:23:54.924346\n",
            "Evaluating: batch 3 begins at 10:23:54.924687\n",
            "Evaluating: batch 3 ends at 10:23:54.928068\n",
            "Evaluating: batch 4 begins at 10:23:54.928314\n",
            "Evaluating: batch 4 ends at 10:23:54.930340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwR1B6JDYzVR",
        "colab_type": "text"
      },
      "source": [
        "## Overview of callback methods\n",
        "\n",
        "\n",
        "### Common methods for training/testing/predicting\n",
        "For training, testing, and predicting, following methods are provided to be overridden.\n",
        "#### `on_(train|test|predict)_begin(self, logs=None)`\n",
        "Called at the beginning of `fit`/`evaluate`/`predict`.\n",
        "#### `on_(train|test|predict)_end(self, logs=None)`\n",
        "Called at the end of `fit`/`evaluate`/`predict`.\n",
        "#### `on_(train|test|predict)_batch_begin(self, batch, logs=None)`\n",
        "Called right before processing a batch during training/testing/predicting. Within this method, `logs` is a dict with `batch` and `size` available keys, representing the current batch number and the size of the batch.\n",
        "#### `on_(train|test|predict)_batch_end(self, batch, logs=None)`\n",
        "Called at the end of training/testing/predicting a batch. Within this method, `logs` is a dict containing the stateful metrics result.\n",
        "\n",
        "### Training specific methods\n",
        "In addition, for training, following are provided.\n",
        "#### on_epoch_begin(self, epoch, logs=None)\n",
        "Called at the beginning of an epoch during training.\n",
        "#### on_epoch_end(self, epoch, logs=None)\n",
        "Called at the end of an epoch during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN5-mCYpXSKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The logs dict contains the loss value, and all the metrics at the end of a batch or epoch. \n",
        "# Example includes the loss and mean absolute error.\n",
        "\n",
        "class LossAndErrorPrintingCallback(tf.keras.callbacks.Callback):\n",
        "  def on_train_batch_end(self, batch, logs=None):\n",
        "    print('For batch {}, loss is {:7.2f}.'.format(batch, logs['loss']))\n",
        "  def on_test_batch_end(self, batch, logs=None):\n",
        "    print('For batch {}, loss is {:7.2f}.'.format(batch, logs['loss']))\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    print('The average loss for epoch {} is {:7.2f} and mean absolute error is {:7.2f}.'.format(epoch, logs['loss'], logs['mae']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRjv98CNZ-_c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "0c18c365-5dac-433b-cbd0-a48c8f133e34"
      },
      "source": [
        "model = get_model()\n",
        "_ = model.fit(x_train, \n",
        "              y_train, \n",
        "              batch_size=64, \n",
        "              steps_per_epoch=5, \n",
        "              epochs=3, \n",
        "              verbose=0, \n",
        "              callbacks=[LossAndErrorPrintingCallback()])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For batch 0, loss is   25.51.\n",
            "For batch 1, loss is  951.36.\n",
            "For batch 2, loss is   17.48.\n",
            "For batch 3, loss is    7.58.\n",
            "For batch 4, loss is    9.36.\n",
            "The average loss for epoch 0 is  202.26 and mean absolute error is    8.25.\n",
            "For batch 0, loss is    6.33.\n",
            "For batch 1, loss is    6.94.\n",
            "For batch 2, loss is    4.42.\n",
            "For batch 3, loss is    6.11.\n",
            "For batch 4, loss is    5.11.\n",
            "The average loss for epoch 1 is    5.78 and mean absolute error is    1.96.\n",
            "For batch 0, loss is    5.29.\n",
            "For batch 1, loss is   11.82.\n",
            "For batch 2, loss is   13.02.\n",
            "For batch 3, loss is   12.89.\n",
            "For batch 4, loss is   16.33.\n",
            "The average loss for epoch 2 is   11.87 and mean absolute error is    2.74.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVYYwiYhaepc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "cce9f2c2-47fe-43ff-9cae-83c23a11b10c"
      },
      "source": [
        "# Similarly, one can provide callbacks in evaluate() calls\n",
        "_ = model.evaluate(x_test, y_test, batch_size=128, verbose=0, steps=20, callbacks=[LossAndErrorPrintingCallback()])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For batch 0, loss is   19.43.\n",
            "For batch 1, loss is   17.19.\n",
            "For batch 2, loss is   18.79.\n",
            "For batch 3, loss is   21.12.\n",
            "For batch 4, loss is   21.87.\n",
            "For batch 5, loss is   18.93.\n",
            "For batch 6, loss is   20.69.\n",
            "For batch 7, loss is   18.88.\n",
            "For batch 8, loss is   19.97.\n",
            "For batch 9, loss is   19.36.\n",
            "For batch 10, loss is   21.17.\n",
            "For batch 11, loss is   22.01.\n",
            "For batch 12, loss is   20.44.\n",
            "For batch 13, loss is   21.44.\n",
            "For batch 14, loss is   20.79.\n",
            "For batch 15, loss is   18.24.\n",
            "For batch 16, loss is   22.60.\n",
            "For batch 17, loss is   22.56.\n",
            "For batch 18, loss is   19.94.\n",
            "For batch 19, loss is   20.48.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA0Pt0DMbBkz",
        "colab_type": "text"
      },
      "source": [
        "## Examples of Keras callback applications\n",
        "\n",
        "### Early stopping at minimum loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mniARh-xa8oY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class EarlyStoppingAtMinLoss(tf.keras.callbacks.Callback):\n",
        "  \"\"\"Stop training when the loss is at its min, i.e. the loss stops decreasing.\n",
        "\n",
        "  Arguments:\n",
        "      patience: Number of epochs to wait after min has been hit. After this\n",
        "      number of no improvement, training stops.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, patience=0):\n",
        "    super(EarlyStoppingAtMinLoss, self).__init__()\n",
        "\n",
        "    self.patience = patience\n",
        "    self.best_weights = None\n",
        "\n",
        "  def on_train_begin(self, logs=None):\n",
        "    self.wait = 0\n",
        "    self.stopped_epoch = 0\n",
        "    self.best = np.Inf\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    current = logs.get('loss')\n",
        "    if np.less(current, self.best):\n",
        "      self.best = current\n",
        "      self.wait = 0\n",
        "      self.best_weights = self.model.get_weights()\n",
        "    else:\n",
        "      self.wait += 1\n",
        "      if self.wait >= self.patience:\n",
        "        self.stopped_epoch = epoch\n",
        "        self.model.stop_training = True\n",
        "        print('Restoring model weights from the end of the best epoch.')\n",
        "        self.model.set_weights(self.best_weights)\n",
        "\n",
        "  def on_train_end(self, logs=None):\n",
        "    if self.stopped_epoch > 0:\n",
        "      print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGI4pcKud8cb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "outputId": "e075c869-06e8-4c0a-d2a0-a570365543b9"
      },
      "source": [
        "model = get_model()\n",
        "_ = model.fit(x_train, \n",
        "              y_train, \n",
        "              batch_size=64, \n",
        "              steps_per_epoch=5, \n",
        "              epochs=30, \n",
        "              verbose=0, \n",
        "              callbacks=[LossAndErrorPrintingCallback(), EarlyStoppingAtMinLoss(patience=5)])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For batch 0, loss is   26.54.\n",
            "For batch 1, loss is  847.82.\n",
            "For batch 2, loss is   23.19.\n",
            "For batch 3, loss is   10.24.\n",
            "For batch 4, loss is   10.92.\n",
            "The average loss for epoch 0 is  183.74 and mean absolute error is    8.14.\n",
            "For batch 0, loss is    6.47.\n",
            "For batch 1, loss is    6.42.\n",
            "For batch 2, loss is    9.08.\n",
            "For batch 3, loss is    7.48.\n",
            "For batch 4, loss is    4.85.\n",
            "The average loss for epoch 1 is    6.86 and mean absolute error is    2.15.\n",
            "For batch 0, loss is    6.47.\n",
            "For batch 1, loss is    6.31.\n",
            "For batch 2, loss is    6.11.\n",
            "For batch 3, loss is    5.67.\n",
            "For batch 4, loss is    3.70.\n",
            "The average loss for epoch 2 is    5.65 and mean absolute error is    1.93.\n",
            "For batch 0, loss is    4.73.\n",
            "For batch 1, loss is    4.19.\n",
            "For batch 2, loss is    3.57.\n",
            "For batch 3, loss is    5.10.\n",
            "For batch 4, loss is    6.08.\n",
            "The average loss for epoch 3 is    4.73 and mean absolute error is    1.75.\n",
            "For batch 0, loss is   14.56.\n",
            "For batch 1, loss is   44.60.\n",
            "For batch 2, loss is  132.68.\n",
            "For batch 3, loss is  150.59.\n",
            "For batch 4, loss is   73.26.\n",
            "The average loss for epoch 4 is   83.14 and mean absolute error is    7.94.\n",
            "For batch 0, loss is   28.98.\n",
            "For batch 1, loss is   26.10.\n",
            "For batch 2, loss is   16.84.\n",
            "For batch 3, loss is   12.73.\n",
            "For batch 4, loss is   11.66.\n",
            "The average loss for epoch 5 is   19.26 and mean absolute error is    3.68.\n",
            "For batch 0, loss is   10.23.\n",
            "For batch 1, loss is    9.42.\n",
            "For batch 2, loss is    6.56.\n",
            "For batch 3, loss is    7.92.\n",
            "For batch 4, loss is   10.55.\n",
            "The average loss for epoch 6 is    8.94 and mean absolute error is    2.44.\n",
            "For batch 0, loss is   13.10.\n",
            "For batch 1, loss is   17.85.\n",
            "For batch 2, loss is   24.17.\n",
            "For batch 3, loss is   48.13.\n",
            "For batch 4, loss is  114.68.\n",
            "The average loss for epoch 7 is   43.58 and mean absolute error is    5.48.\n",
            "For batch 0, loss is  159.80.\n",
            "For batch 1, loss is   79.05.\n",
            "For batch 2, loss is   40.50.\n",
            "For batch 3, loss is   13.94.\n",
            "For batch 4, loss is    8.59.\n",
            "The average loss for epoch 8 is   60.38 and mean absolute error is    6.23.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00009: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm8L14eod8iX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}